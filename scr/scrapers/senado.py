#!/usr/bin/env python3
"""
Script para testar o SenadoScraper melhorado
"""
import sys
import os
from datetime import datetime

# Adiciona o diret√≥rio do projeto ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importe seu scraper (ajuste o caminho conforme sua estrutura)
# from scrapers.senado import SenadoScraper

def test_scraper():
    """Testa o scraper e mostra os resultados"""
    print("üöÄ Iniciando teste do SenadoScraper...")
    print("=" * 60)
    
    try:
        # Inicializa o scraper
        scraper = SenadoScraper()
        
        # Coleta apenas 1 p√°gina para teste r√°pido
        print("üì∞ Coletando not√≠cias do Senado (1 p√°gina)...")
        news = scraper.scrape(max_pages=1)
        
        print(f"\n‚úÖ Coletadas {len(news)} not√≠cias!")
        print("=" * 60)
        
        # Mostra as primeiras 5 not√≠cias
        for i, item in enumerate(news[:5], 1):
            print(f"\nüìã NOT√çCIA {i}:")
            print(f"T√≠tulo: {item['titulo']}")
            print(f"Data Pub: {item['data_publicacao']}")
            print(f"Resumo: {item['resumo'][:100]}{'...' if len(item['resumo']) > 100 else ''}")
            print(f"Link: {item['link']}")
            print("-" * 40)
        
        # Estat√≠sticas
        print(f"\nüìä ESTAT√çSTICAS:")
        com_data = sum(1 for item in news if item['data_publicacao'])
        com_resumo = sum(1 for item in news if item['resumo'])
        
        print(f"Total de not√≠cias: {len(news)}")
        print(f"Com data de publica√ß√£o: {com_data} ({com_data/len(news)*100:.1f}%)")
        print(f"Com resumo: {com_resumo} ({com_resumo/len(news)*100:.1f}%)")
        
        # Verifica se h√° t√≠tulos com datas
        titulos_com_data = []
        for item in news:
            if re.search(r'\d{2}/\d{2}/\d{4}', item['titulo']):
                titulos_com_data.append(item['titulo'])
        
        if titulos_com_data:
            print(f"\n‚ö†Ô∏è ATEN√á√ÉO: {len(titulos_com_data)} t√≠tulos ainda cont√™m datas:")
            for titulo in titulos_com_data[:3]:
                print(f"  - {titulo[:80]}...")
        else:
            print("\n‚úÖ Nenhum t√≠tulo cont√©m datas! Perfeito!")
        
        # Salva resultado em JSON para an√°lise
        save_results(news)
        
    except Exception as e:
        print(f"‚ùå Erro durante o teste: {e}")
        import traceback
        traceback.print_exc()

def save_results(news):
    """Salva os resultados em um arquivo JSON"""
    import json
    
    filename = f"test_senado_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(news, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Resultados salvos em: {filename}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao salvar: {e}")

def test_individual_functions():
    """Testa fun√ß√µes espec√≠ficas do scraper"""
    print("\nüîß TESTANDO FUN√á√ïES INDIVIDUAIS:")
    print("=" * 60)
    
    try:
        import re
        scraper = SenadoScraper()
        
        # Teste de limpeza de t√≠tulo
        test_titles = [
            "04/09/2025 20h38 CPMI: presidente da Conafer nega irregularidades e apela ao sil√™ncio",
            "04/09/2025 19h25 CPMI aprova rastrear visitas do 'careca do INSS' ao Congresso",
            "04/09/2025 18h38 √Ä CPMI, diretora aponta que CGU audita todas as entidades ligadas ao INSS",
            "Proposto pelo Senado, Estatuto do Pantanal vai √† san√ß√£o"
        ]
        
        print("üìù Teste de limpeza de t√≠tulos:")
        for title in test_titles:
            clean = scraper._clean_title(title)
            date = scraper._extract_date_from_title(title)
            print(f"\nOriginal: {title}")
            print(f"Limpo:    {clean}")
            print(f"Data:     {date}")
            print("-" * 40)
        
        # Teste de extra√ß√£o de data da URL
        print("\nüîó Teste de extra√ß√£o de data da URL:")
        test_urls = [
            "/noticias/materias/2025/09/04/cpmi-ex-presidente-do-inss",
            "/noticias/materias/2024/12/15/projeto-aprovado-senado"
        ]
        
        for url in test_urls:
            date = scraper._extract_date_from_url(url)
            print(f"URL:  {url}")
            print(f"Data: {date}")
            print("-" * 40)
            
    except Exception as e:
        print(f"‚ùå Erro nos testes individuais: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import re
    
    print("üß™ TESTE DO SENADO SCRAPER")
    print("=" * 60)
    
    # Teste principal
    test_scraper()
    
    # Teste de fun√ß√µes individuais
    test_individual_functions()
    
    print("\n‚ú® Teste finalizado!")
    print("\nüí° Pr√≥ximo passo: Atualize o c√≥digo no GitHub e monitore os resultados!")
